{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/aind/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 80\n",
    "max_length = 30\n",
    "X_vocab_size = 26\n",
    "y_vocab_size = 26\n",
    "embed_size = 20\n",
    "rnn_hidden_unit = 50\n",
    "align_hidden_unit = rnn_hidden_unit\n",
    "maxout_hidden_unit = rnn_hidden_unit // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "START_TOKEN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = [tf.placeholder(tf.int32, (batch_size,), \"X_{}\".format(i)) for i in range(max_length)]\n",
    "y = [tf.placeholder(tf.int32, (batch_size,), \"y_{}\".format(i)) for i in range(max_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_embed = tf.get_variable(\"X_embed\", [X_vocab_size, embed_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_forward = tf.get_variable(\"W_forward\", [embed_size, rnn_hidden_unit])\n",
    "W_forward_z = tf.get_variable(\"W_forward_z\", [embed_size, rnn_hidden_unit])\n",
    "W_forward_r = tf.get_variable(\"W_forward_r\", [embed_size, rnn_hidden_unit])\n",
    "\n",
    "U_forward = tf.get_variable(\"U_forward\", [rnn_hidden_unit, rnn_hidden_unit])\n",
    "U_forward_z = tf.get_variable(\"U_forward_z\", [rnn_hidden_unit, rnn_hidden_unit])\n",
    "U_forward_r = tf.get_variable(\"U_forward_r\", [rnn_hidden_unit, rnn_hidden_unit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h_forward = []\n",
    "h_forward_init = tf.zeros([batch_size, rnn_hidden_unit], name=\"h_forward_init\")\n",
    "\n",
    "for i, x_i in enumerate(X):\n",
    "    Ex_i = tf.nn.embedding_lookup(X_embed, x_i)\n",
    "    h_i_prev = h_forward[i-1] if i > 0 else h_forward_init\n",
    "    z_i = tf.sigmoid(tf.matmul(Ex_i, W_forward_z) + tf.matmul(h_i_prev, U_forward_z))\n",
    "    r_i = tf.sigmoid(tf.matmul(Ex_i, W_forward_r) + tf.matmul(h_i_prev, U_forward_r))\n",
    "    h__i = tf.tanh(tf.matmul(Ex_i, W_forward) + tf.matmul(tf.multiply(r_i, h_i_prev), U_forward))\n",
    "    h_i = tf.add(tf.multiply((1 - z_i), h_i_prev), tf.multiply(z_i, h__i), name=\"h_forward_{}\".format(i))\n",
    "    h_forward.append(h_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_backward = tf.get_variable(\"W_backward\", [embed_size, rnn_hidden_unit])\n",
    "W_backward_z = tf.get_variable(\"W_backward_z\", [embed_size, rnn_hidden_unit])\n",
    "W_backward_r = tf.get_variable(\"W_backward_r\", [embed_size, rnn_hidden_unit])\n",
    "\n",
    "U_backward = tf.get_variable(\"U_backward\", [rnn_hidden_unit, rnn_hidden_unit])\n",
    "U_backward_z = tf.get_variable(\"U_backward_z\", [rnn_hidden_unit, rnn_hidden_unit])\n",
    "U_backward_r = tf.get_variable(\"U_backward_r\", [rnn_hidden_unit, rnn_hidden_unit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h_backward = []\n",
    "h_backward_init = tf.zeros([batch_size, rnn_hidden_unit], name=\"h_backward_init\")\n",
    "\n",
    "for i, x_i in reversed(list(enumerate(X))):\n",
    "    Ex_i = tf.nn.embedding_lookup(X_embed, x_i)\n",
    "    h_i_prev = h_forward[i-1] if i > 0 else h_backward_init\n",
    "    z_i = tf.sigmoid(tf.matmul(Ex_i, W_backward_z) + tf.matmul(h_i_prev, U_backward_z))\n",
    "    r_i = tf.sigmoid(tf.matmul(Ex_i, W_backward_r) + tf.matmul(h_i_prev, U_backward_r))\n",
    "    h__i = tf.tanh(tf.matmul(Ex_i, W_backward) + tf.matmul(tf.multiply(r_i, h_i_prev), U_backward))\n",
    "    h_i = tf.add(tf.multiply((1 - z_i), h_i_prev), tf.multiply(z_i, h__i), name=\"h_backward_{}\".format(i))\n",
    "    h_backward.insert(0, h_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h = [tf.concat([h_forward_i, h_backward_i], axis=1, name=\"h_{}\".format(i)) \n",
    "     for i, (h_forward_i, h_backward_i) in enumerate(zip(h_forward, h_backward))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_embed = tf.get_variable('y_embed', [y_vocab_size, embed_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_dec = tf.get_variable(\"W_dec\", [embed_size, rnn_hidden_unit])\n",
    "W_dec_z = tf.get_variable(\"W_dec_z\", [embed_size, rnn_hidden_unit])\n",
    "W_dec_r = tf.get_variable(\"W_dec_r\", [embed_size, rnn_hidden_unit])\n",
    "\n",
    "U_dec = tf.get_variable(\"U_dec\", [rnn_hidden_unit, rnn_hidden_unit])\n",
    "U_dec_z = tf.get_variable(\"U_dec_z\", [rnn_hidden_unit, rnn_hidden_unit])\n",
    "U_dec_r = tf.get_variable(\"U_dec_r\", [rnn_hidden_unit, rnn_hidden_unit])\n",
    "\n",
    "C_dec = tf.get_variable(\"C_dec\", [rnn_hidden_unit*2, rnn_hidden_unit])\n",
    "C_dec_z = tf.get_variable(\"C_dec_z\", [rnn_hidden_unit*2, rnn_hidden_unit])\n",
    "C_dec_r = tf.get_variable(\"C_dec_r\", [rnn_hidden_unit*2, rnn_hidden_unit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_s = tf.get_variable(\"W_s\", [rnn_hidden_unit, rnn_hidden_unit])\n",
    "W_a = tf.get_variable(\"W_a\", [rnn_hidden_unit, align_hidden_unit])\n",
    "U_a = tf.get_variable(\"U_a\", [rnn_hidden_unit*2, align_hidden_unit])\n",
    "v_a = tf.get_variable(\"v_a\", [1, align_hidden_unit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_o = tf.get_variable(\"W_o\", [maxout_hidden_unit, y_vocab_size])\n",
    "U_o = tf.get_variable(\"U_o\", [rnn_hidden_unit, maxout_hidden_unit*2])\n",
    "V_o = tf.get_variable(\"V_o\", [embed_size, maxout_hidden_unit*2])\n",
    "C_o = tf.get_variable(\"C_o\", [rnn_hidden_unit*2, maxout_hidden_unit*2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"t_0_3/Max:0\", shape=(80, 25), dtype=float32)\n",
      "Tensor(\"MatMul_3515:0\", shape=(80, 26), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "s = []\n",
    "s_init = tf.tanh(tf.matmul(h_backward[0], W_s), name=\"s_init\")\n",
    "y_init = tf.fill(y[0].shape, START_TOKEN, name=\"y_init\")\n",
    "logits = []\n",
    "\n",
    "for i, y_i in enumerate(y):\n",
    "    y_i_prev = y[i-1] if i > 0 else y_init\n",
    "    s_i_prev = s[i-1] if i > 0 else s_init\n",
    "    \n",
    "    e_i = []\n",
    "    for j, h_j in enumerate(h):\n",
    "        e_i_j = tf.matmul(\n",
    "            tf.tanh(tf.matmul(s_i_prev, W_a) + tf.matmul(h_j, U_a)),\n",
    "            tf.transpose(v_a),\n",
    "            name=\"e_{}_{}\".format(i, j))\n",
    "        e_i.append(e_i_j)\n",
    "    e_i_sum = tf.reduce_sum(tf.exp(e_i), axis=0)\n",
    "    alpha_i = [tf.multiply(e_ij, 1/e_i_sum, name=\"alpha_{}_{}\".format(i, j)) for j, e_ij in enumerate(e_i)]\n",
    "    weighted_c_i = [tf.multiply(alpha_i_j, h_j) for alpha_i_j, h_j in zip(alpha_i, h)]\n",
    "    c_i = tf.reduce_sum(weighted_c_i, axis=0, name=\"c_{}\".format(i))\n",
    "    \n",
    "    Ey_i_prev = tf.nn.embedding_lookup(y_embed, y_i)\n",
    "    z_i = tf.sigmoid(tf.matmul(Ey_i_prev, W_dec_z) + \n",
    "                    tf.matmul(s_i_prev, U_dec_z) +\n",
    "                    tf.matmul(c_i, C_dec_z))\n",
    "    r_i = tf.sigmoid(tf.matmul(Ey_i_prev, W_dec_r) + \n",
    "                tf.matmul(s_i_prev, U_dec_r) +\n",
    "                tf.matmul(c_i, C_dec_r))\n",
    "    s__i = tf.tanh(tf.matmul(Ey_i_prev, W_dec) +\n",
    "                  tf.matmul(tf.multiply(r_i, s_i_prev), U_dec) +\n",
    "                  tf.matmul(c_i, C_dec))\n",
    "    s_i = tf.add(tf.multiply(1-z_i, s_i_prev), tf.multiply(z_i, s__i), name=\"s_{}\".format(i))\n",
    "    s.append(s_i)\n",
    "    \n",
    "    t__i = tf.matmul(s_i_prev, U_o) + tf.matmul(Ey_i_prev, V_o) + tf.matmul(c_i, C_o)\n",
    "    t_i = tf.contrib.layers.maxout(t__i, maxout_hidden_unit, axis=1, name=\"t_{}\".format(i))\n",
    "    logits.append(t_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
